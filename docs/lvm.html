<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="psychonetrics LVM family: Latent variable models, CFA, SEM, and latent/residual network models">
  <title>LVM Family | psychonetrics</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>

<!-- Navigation -->
<nav class="navbar">
  <div class="container nav-container">
    <a href="index.html" class="nav-brand">psychonetrics</a>
    <button class="nav-toggle" aria-label="Toggle navigation">&#9776;</button>
    <ul class="nav-menu">
      <li><a href="index.html" class="nav-link">Home</a></li>
      <li><a href="tutorial.html" class="nav-link">Tutorial</a></li>
      <li class="nav-dropdown">
        <button class="nav-link dropdown-toggle" aria-expanded="false" aria-haspopup="true">
          Models <svg class="dropdown-chevron" width="10" height="6" viewBox="0 0 10 6" fill="none"><path d="M1 1L5 5L9 1" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/></svg>
        </button>
        <ul class="dropdown-menu">
          <li><a href="varcov.html" class="nav-link">Varcov</a></li>
          <li><a href="lvm.html" class="nav-link">LVM</a></li>
          <li><a href="ising.html" class="nav-link">Ising</a></li>
          <li><a href="var1.html" class="nav-link">Var1</a></li>
          <li><a href="dlvm1.html" class="nav-link">DLVM1</a></li>
        </ul>
      </li>
      <li><a href="examples.html" class="nav-link">Examples</a></li>
      <li><a href="about.html" class="nav-link">About</a></li>
    </ul>
  </div>
</nav>

<!-- Page Header -->
<div class="page-header container container-narrow">
  <h1>LVM Family</h1>
  <p class="subtitle">Latent variable models: CFA, SEM, and network extensions</p>
</div>

<main class="container container-narrow">

<!-- Table of Contents -->
<div class="toc">
  <h3>Contents</h3>
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#matrices">Core Matrices</a></li>
    <li><a href="#wrappers">Wrapper Functions</a></li>
    <li><a href="#example-cfa">Example: CFA on HolzingerSwineford1939</a></li>
    <li><a href="#example-lnm">Example: Latent Network Model (LNM)</a></li>
    <li><a href="#example-rnm">Example: Residual Network Model (RNM)</a></li>
    <li><a href="#example-sem">Example: SEM with Structural Paths</a></li>
    <li><a href="#example-invariance">Example: Measurement Invariance</a></li>
    <li><a href="#summary">Summary</a></li>
  </ul>
</div>

<!-- Overview Section -->
<section id="overview">
  <h2>Overview</h2>
  <p>
    The <strong>lvm</strong> family implements latent variable models, including confirmatory factor analysis (CFA) and structural equation models (SEM). The key innovation is that both latent covariance matrices and residual covariance matrices can independently be modeled as networks (Gaussian Graphical Models).
  </p>
  <p>
    The mathematical model for latent variable models is:
  </p>
  <div class="note">
    <p><strong>Expected values:</strong></p>
    <p>$$\text{E}(\boldsymbol{y}) = \boldsymbol{\nu} + \boldsymbol{\Lambda}(\boldsymbol{I} - \boldsymbol{B})^{-1}\boldsymbol{\nu}_\eta$$</p>
    <p><strong>Variance-covariance structure:</strong></p>
    <p>$$\text{var}(\boldsymbol{y}) = \boldsymbol{\Lambda}(\boldsymbol{I} - \boldsymbol{B})^{-1}\boldsymbol{\Sigma}_\zeta(\boldsymbol{I} - \boldsymbol{B})^{-1\prime}\boldsymbol{\Lambda}^\prime + \boldsymbol{\Sigma}_\varepsilon$$</p>
  </div>
  <p>Where:</p>
  <ul>
    <li><strong>&Lambda;</strong> (lambda) is the factor loading matrix linking observed variables to latent variables</li>
    <li><strong>B</strong> (beta) is the matrix of structural paths between latent variables</li>
    <li><strong>&Sigma;<sub>&zeta;</sub></strong> (sigma_zeta) is the latent variable covariance matrix</li>
    <li><strong>&Sigma;<sub>&epsilon;</sub></strong> (sigma_epsilon) is the residual covariance matrix</li>
    <li><strong>&nu;</strong> (nu) is the vector of observed intercepts</li>
    <li><strong>&nu;<sub>&eta;</sub></strong> (nu_eta) is the vector of latent intercepts</li>
  </ul>
</section>

<!-- Core Matrices Section -->
<section id="matrices">
  <h2>Core Matrices</h2>
  <p>
    The lvm family uses several matrices to specify the model structure. The table below summarizes all core matrices:
  </p>
  <table>
    <thead>
      <tr>
        <th>Matrix</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>lambda</code></td>
        <td>Factor loadings (observed &rarr; latent)</td>
        <td>User-specified</td>
      </tr>
      <tr>
        <td><code>beta</code></td>
        <td>Structural paths between latent variables</td>
        <td><code>"zero"</code></td>
      </tr>
      <tr>
        <td><code>nu</code></td>
        <td>Observed variable intercepts</td>
        <td>Estimated</td>
      </tr>
      <tr>
        <td><code>nu_eta</code></td>
        <td>Latent variable intercepts</td>
        <td>Estimated</td>
      </tr>
      <tr>
        <td><code>tau</code></td>
        <td>Thresholds (for ordinal data) <em style="color:var(--nus-orange);">[experimental]</em></td>
        <td>Estimated</td>
      </tr>
    </tbody>
  </table>

  <h3>Latent Covariance Decomposition</h3>
  <p>
    The latent covariance matrix <strong>&Sigma;<sub>&zeta;</sub></strong> can be parameterized in different ways using the <code>latent</code> argument:
  </p>
  <table>
    <thead>
      <tr>
        <th>Latent Type</th>
        <th>Matrices</th>
        <th>Equation</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>"cov"</code></td>
        <td><code>sigma_zeta</code></td>
        <td>$\boldsymbol{\Sigma}_\zeta$ (directly estimated)</td>
      </tr>
      <tr>
        <td><code>"chol"</code></td>
        <td><code>lowertri_zeta</code></td>
        <td>$\boldsymbol{\Sigma}_\zeta = \boldsymbol{L}_\zeta\boldsymbol{L}_\zeta'$</td>
      </tr>
      <tr>
        <td><code>"prec"</code></td>
        <td><code>kappa_zeta</code></td>
        <td>$\boldsymbol{\Sigma}_\zeta = \boldsymbol{K}_\zeta^{-1}$</td>
      </tr>
      <tr>
        <td><code>"ggm"</code></td>
        <td><code>omega_zeta</code>, <code>delta_zeta</code></td>
        <td>$\boldsymbol{\Sigma}_\zeta = \boldsymbol{\Delta}_\zeta(\boldsymbol{I} - \boldsymbol{\Omega}_\zeta)^{-1}\boldsymbol{\Delta}_\zeta$</td>
      </tr>
    </tbody>
  </table>

  <h3>Residual Covariance Decomposition</h3>
  <p>
    Similarly, the residual covariance matrix <strong>&Sigma;<sub>&epsilon;</sub></strong> can be parameterized using the <code>residual</code> argument:
  </p>
  <table>
    <thead>
      <tr>
        <th>Residual Type</th>
        <th>Matrices</th>
        <th>Equation</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>"cov"</code></td>
        <td><code>sigma_epsilon</code></td>
        <td>$\boldsymbol{\Sigma}_\varepsilon$ (directly estimated)</td>
      </tr>
      <tr>
        <td><code>"chol"</code></td>
        <td><code>lowertri_epsilon</code></td>
        <td>$\boldsymbol{\Sigma}_\varepsilon = \boldsymbol{L}_\varepsilon\boldsymbol{L}_\varepsilon'$</td>
      </tr>
      <tr>
        <td><code>"prec"</code></td>
        <td><code>kappa_epsilon</code></td>
        <td>$\boldsymbol{\Sigma}_\varepsilon = \boldsymbol{K}_\varepsilon^{-1}$</td>
      </tr>
      <tr>
        <td><code>"ggm"</code></td>
        <td><code>omega_epsilon</code>, <code>delta_epsilon</code></td>
        <td>$\boldsymbol{\Sigma}_\varepsilon = \boldsymbol{\Delta}_\varepsilon(\boldsymbol{I} - \boldsymbol{\Omega}_\varepsilon)^{-1}\boldsymbol{\Delta}_\varepsilon$</td>
      </tr>
    </tbody>
  </table>
</section>

<!-- Wrapper Functions Section -->
<section id="wrappers">
  <h2>Wrapper Functions</h2>
  <p>
    The lvm family provides several wrapper functions that set appropriate defaults for common model types:
  </p>
  <table>
    <thead>
      <tr>
        <th>Wrapper</th>
        <th>What it sets</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>lvm()</code></td>
        <td>User chooses</td>
        <td>Base function for general latent variable models</td>
      </tr>
      <tr>
        <td><code>lnm()</code></td>
        <td><code>latent = "ggm"</code></td>
        <td>Latent Network Model (network among latent factors)</td>
      </tr>
      <tr>
        <td><code>rnm()</code></td>
        <td><code>residual = "ggm"</code></td>
        <td>Residual Network Model (network among residuals)</td>
      </tr>
      <tr>
        <td><code>lrnm()</code></td>
        <td>Both <code>latent</code> and <code>residual = "ggm"</code></td>
        <td>Combined Latent + Residual Network Model</td>
      </tr>
      <tr>
        <td><code>bifactor()</code></td>
        <td>Augmented $\boldsymbol{\Lambda}$, diagonal latent cov</td>
        <td>Bifactor model with general + specific factors</td>
      </tr>
      <tr>
        <td><code>latentgrowth()</code></td>
        <td>$\boldsymbol{\Lambda}$ from time, intercept + slope</td>
        <td>Latent growth curve model</td>
      </tr>
    </tbody>
  </table>

  <h3>Identification</h3>
  <p>
    Latent variable models require identification constraints. The <code>identification</code> argument specifies how to achieve this:
  </p>
  <ul>
    <li><code>"loadings"</code>: Fix the first loading of each factor to 1 (default). This allows latent variances to be freely estimated.</li>
    <li><code>"variance"</code>: Fix latent variances to 1. This allows all factor loadings to be freely estimated.</li>
  </ul>
  <div class="note">
    <p><strong>Note:</strong> When using <code>identification = "loadings"</code>, the first loading of each factor is fixed to 1, so the first indicator for each latent variable must have a non-zero loading on that factor.</p>
  </div>
</section>

<!-- Example: CFA Section -->
<section id="example-cfa">
  <h2>Example: CFA on HolzingerSwineford1939</h2>
  <p>
    The classic Holzinger-Swineford dataset includes 9 mental ability tests measuring 3 latent factors: visual, textual, and speed abilities. This example demonstrates how to specify and estimate a confirmatory factor analysis model.
  </p>
  <p>
    The key to specifying a CFA in psychonetrics is constructing the <strong>lambda</strong> matrix, where rows represent observed variables and columns represent latent factors. A value of <code>1</code> indicates a free loading to be estimated, while <code>0</code> indicates the loading is fixed to zero.
  </p>
  <pre><code class="language-r">library("psychonetrics")
library("lavaan")
data(HolzingerSwineford1939)

# Define factor loading structure
# Rows = observed variables (9 tests)
# Columns = latent factors (3 factors)
Lambda <- matrix(0, 9, 3)
Lambda[1:3, 1] <- 1  # Visual factor: x1, x2, x3
Lambda[4:6, 2] <- 1  # Textual factor: x4, x5, x6
Lambda[7:9, 3] <- 1  # Speed factor: x7, x8, x9

# Fit CFA model
mod_cfa <- lvm(HolzingerSwineford1939,
               lambda = Lambda,
               vars = paste0("x", 1:9),
               latents = c("visual", "textual", "speed"),
               identification = "variance")
mod_cfa <- mod_cfa %>% runmodel

# Inspect results
mod_cfa %>% fit
mod_cfa %>% parameters
mod_cfa %>% MIs</code></pre>
  <p>
    The <code>identification = "variance"</code> argument fixes all latent variances to 1, allowing all factor loadings to be freely estimated.
  </p>
</section>

<!-- Example: LNM Section -->
<section id="example-lnm">
  <h2>Example: Latent Network Model (LNM)</h2>
  <p>
    A Latent Network Model estimates the covariances among latent factors as a Gaussian Graphical Model. Instead of freely estimating all correlations, the model estimates a sparse network of partial correlations among the latent factors.
  </p>
  <div class="note">
    <p><strong>Important:</strong> A saturated LNM is always equivalent to a CFA model. The typical workflow is to first fit a CFA model and, if it fits well, reparameterize the latent covariance structure as a network and search for a sparse latent network using <code>prune()</code>.</p>
  </div>
  <pre><code class="language-r"># Latent Network Model
mod_lnm <- lnm(HolzingerSwineford1939,
               lambda = Lambda,
               vars = paste0("x", 1:9),
               latents = c("visual", "textual", "speed"),
               identification = "variance")
mod_lnm <- mod_lnm %>% runmodel

# Inspect latent network parameters
mod_lnm %>% parameters

# Prune non-significant latent edges
mod_lnm <- mod_lnm %>% prune(alpha = 0.01)

# Extract latent network (omega_zeta matrix)
omega_latent <- getmatrix(mod_lnm, "omega_zeta")

# Compare CFA vs LNM
compare(cfa = mod_cfa, lnm = mod_lnm)

# Visualize latent network
library("qgraph")
qgraph(omega_latent,
       labels = c("visual", "textual", "speed"),
       theme = "colorblind",
       cut = 0,
       vsize = 15)</code></pre>
  <p>
    The <code>omega_zeta</code> matrix contains partial correlations between latent factors, controlling for all other latent factors. This provides insight into direct relationships among latent constructs.
  </p>
</section>

<!-- Example: RNM Section -->
<section id="example-rnm">
  <h2>Example: Residual Network Model (RNM)</h2>
  <p>
    A Residual Network Model estimates a network among the residuals of observed variables, after accounting for the latent factors. This can reveal conditional dependencies between observed variables that are not explained by the latent factor structure.
  </p>
  <p>
    Residual networks are particularly useful for detecting local dependencies and method effects that violate local independence assumptions in traditional CFA.
  </p>
  <pre><code class="language-r"># Residual Network Model (start with empty residual network)
mod_rnm <- rnm(HolzingerSwineford1939,
               lambda = Lambda,
               vars = paste0("x", 1:9),
               latents = c("visual", "textual", "speed"),
               identification = "variance",
               omega_epsilon = "empty")  # Start with no residual edges
mod_rnm <- mod_rnm %>% runmodel

# Search for significant residual edges
mod_rnm <- mod_rnm %>% stepup(alpha = 0.01, criterion = "bic")

# Inspect residual network
mod_rnm %>% parameters
omega_resid <- getmatrix(mod_rnm, "omega_epsilon")

# Visualize residual network
qgraph(omega_resid,
       labels = paste0("x", 1:9),
       theme = "colorblind",
       cut = 0,
       layout = "spring")</code></pre>
  <p>
    The <code>omega_epsilon</code> matrix contains partial correlations between observed variable residuals. Non-zero edges indicate relationships between variables that are not captured by the latent factor structure alone.
  </p>

  <h3>RNM with Pseudo-Maximum Likelihood (PML) <em style="color:var(--nus-orange);">[experimental]</em></h3>
  <p>
    With ML estimation, an RNM with a saturated (full) residual network is not identified because the CFA model plus all residual edges is overparameterized. PML estimation avoids this problem by estimating the model based on bivariate marginal likelihoods, which makes even a saturated residual network identified. This allows a top-down approach: start with a full residual network and prune non-significant edges.
  </p>
  <div class="note">
    <p><strong>Note:</strong> PML is an experimental feature and has not yet been fully validated.</p>
  </div>
  <pre><code class="language-r"># RNM with PML: start with a full residual network
mod_rnm_pml <- rnm(HolzingerSwineford1939,
                    lambda = Lambda,
                    vars = paste0("x", 1:9),
                    latents = c("visual", "textual", "speed"),
                    identification = "variance",
                    omega_epsilon = "full",
                    estimator = "PML")
mod_rnm_pml <- mod_rnm_pml %>% runmodel

# Prune non-significant residual edges
mod_rnm_pml <- mod_rnm_pml %>% prune(alpha = 0.01)

# Inspect and visualize
mod_rnm_pml %>% parameters
omega_resid_pml <- getmatrix(mod_rnm_pml, "omega_epsilon")
qgraph(omega_resid_pml,
       labels = paste0("x", 1:9),
       theme = "colorblind",
       cut = 0,
       layout = "spring")</code></pre>
</section>

<!-- Example: SEM Section -->
<section id="example-sem">
  <h2>Example: SEM with Structural Paths</h2>
  <p>
    Structural equation models extend CFA by adding directional paths between latent variables. This example uses the classic <code>PoliticalDemocracy</code> dataset from lavaan, modeling the effect of industrialization in 1960 on democracy in 1960 and 1965.
  </p>
  <p>
    The <strong>beta</strong> matrix specifies structural paths between latent variables. In the beta matrix, rows represent outcome variables and columns represent predictor variables.
  </p>
  <pre><code class="language-r">data(PoliticalDemocracy)

# Factor loadings
# ind60: x1, x2, x3 (industrialization indicators)
# dem60: y1, y2, y3, y4 (democracy 1960)
# dem65: y5, y6, y7, y8 (democracy 1965)
Lambda <- matrix(0, 11, 3)
Lambda[1:3, 1] <- 1   # ind60 indicators: x1, x2, x3
Lambda[4:7, 2] <- 1   # dem60 indicators: y1, y2, y3, y4
Lambda[8:11, 3] <- 1  # dem65 indicators: y5, y6, y7, y8

# Structural paths (beta matrix)
# Rows = outcomes, Columns = predictors
Beta <- matrix(0, 3, 3)
Beta[2, 1] <- 1  # dem60 ~ ind60
Beta[3, 1] <- 1  # dem65 ~ ind60
Beta[3, 2] <- 1  # dem65 ~ dem60

# Equality constraints on factor loadings
# Loadings of corresponding items in dem60 and dem65 are equal
Lambda[5, 2] <- 2; Lambda[9, 3] <- 2   # y2 == y6
Lambda[6, 2] <- 3; Lambda[10, 3] <- 3  # y3 == y7
Lambda[7, 2] <- 4; Lambda[11, 3] <- 4  # y4 == y8

# Residual covariances (correlated errors across time)
Theta <- diag(1, 11)
Theta[4, 8] <- Theta[8, 4] <- 1   # y1 ~~ y5
Theta[5, 9] <- Theta[9, 5] <- 1   # y2 ~~ y6
Theta[6, 10] <- Theta[10, 6] <- 1 # y3 ~~ y7
Theta[7, 11] <- Theta[11, 7] <- 1 # y4 ~~ y8

# Fit SEM model
mod_sem <- lvm(PoliticalDemocracy,
               lambda = Lambda,
               beta = Beta,
               sigma_epsilon = Theta,
               vars = c(paste0("x", 1:3), paste0("y", 1:8)),
               latents = c("ind60", "dem60", "dem65"),
               identification = "loadings")
mod_sem <- mod_sem %>% runmodel

# Inspect results
mod_sem %>% fit
mod_sem %>% parameters</code></pre>
  <p>
    <strong>Key points:</strong>
  </p>
  <ul>
    <li>Values in the beta matrix greater than 1 represent equality constraints (parameters with the same number are constrained equal)</li>
    <li>The same applies to the lambda and sigma_epsilon matrices</li>
    <li><code>identification = "loadings"</code> fixes the first loading of each factor to 1</li>
    <li>Correlated residuals between corresponding dem60 and dem65 indicators are specified via <code>sigma_epsilon</code></li>
  </ul>
</section>

<!-- Example: Measurement Invariance Section -->
<section id="example-invariance">
  <h2>Example: Measurement Invariance</h2>
  <p>
    Measurement invariance testing examines whether a measurement model operates equivalently across groups. This is essential for valid group comparisons. psychonetrics supports multi-group analysis with flexible equality constraints.
  </p>
  <p>
    This example uses the <code>StarWars</code> dataset to test measurement invariance of a three-factor model across age groups (young vs. older fans).
  </p>
  <pre><code class="language-r">data(StarWars)

# Define measurement model
# Q1 cross-loads on all three factors
Lambda <- matrix(0, 10, 3)
Lambda[1:4, 1] <- 1      # Prequels: Q1, Q2, Q3, Q4
Lambda[c(1,5:7), 2] <- 1 # Original trilogy: Q1, Q5, Q6, Q7
Lambda[c(1,8:10), 3] <- 1 # Sequels: Q1, Q8, Q9, Q10

obsvars <- paste0("Q", 1:10)
latents <- c("Prequels", "Original", "Sequels")

# Create age groups
StarWars$agegroup <- ifelse(StarWars$Q12 < 30, "young", "older")

# Configural invariance (free across groups)
mod_config <- lvm(StarWars,
                  lambda = Lambda,
                  vars = obsvars,
                  latents = latents,
                  identification = "variance",
                  groups = "agegroup")
mod_config <- mod_config %>% runmodel

# Weak invariance (equal loadings)
mod_weak <- mod_config %>% groupequal("lambda") %>% runmodel

# Strong invariance (equal intercepts)
mod_strong <- mod_weak %>% groupequal("nu") %>% runmodel

# Strict invariance (equal residual variances)
mod_strict <- mod_strong %>% groupequal("sigma_epsilon") %>% runmodel

# Compare all levels of invariance
compare(configural = mod_config,
        weak = mod_weak,
        strong = mod_strong,
        strict = mod_strict)</code></pre>
  <p>
    <strong>Levels of measurement invariance:</strong>
  </p>
  <ul>
    <li><strong>Configural:</strong> Same model structure across groups (no equality constraints)</li>
    <li><strong>Weak (metric):</strong> Equal factor loadings (<code>lambda</code>)</li>
    <li><strong>Strong (scalar):</strong> Equal intercepts (<code>nu</code>) in addition to loadings</li>
    <li><strong>Strict:</strong> Equal residual variances (<code>sigma_epsilon</code>) in addition to loadings and intercepts</li>
  </ul>
  <p>
    The <code>compare()</code> function provides chi-square difference tests and fit indices to evaluate whether invariance constraints are tenable.
  </p>
</section>

<!-- Summary Section -->
<section id="summary">
  <h2>Summary</h2>
  <p>
    The <strong>lvm</strong> family provides a flexible and powerful framework for estimating latent variable models in psychonetrics. Key features include:
  </p>
  <ul>
    <li><strong>Confirmatory Factor Analysis (CFA):</strong> Standard measurement models with freely estimated latent covariances</li>
    <li><strong>Structural Equation Models (SEM):</strong> Directional paths between latent variables via the beta matrix</li>
    <li><strong>Latent Network Models (LNM):</strong> Model latent covariances as a sparse network of partial correlations</li>
    <li><strong>Residual Network Models (RNM):</strong> Model residual covariances as a network, revealing local dependencies</li>
    <li><strong>Multi-group analysis:</strong> Full support for measurement invariance testing across groups</li>
    <li><strong>Flexible parameterizations:</strong> Choose between covariance, precision, Cholesky, or GGM decompositions for both latent and residual structures</li>
  </ul>
  <p>
    For more examples and applications, see the <a href="examples.html">Examples</a> page. For general information on working with psychonetrics models (e.g., model modification, pruning, stepwise search), see the <a href="tutorial.html">General Tutorial</a>.
  </p>
</section>

</main>

<!-- Footer -->
<footer>
  <div class="container footer-grid">
    <div>
      <h4>psychonetrics</h4>
      <p>An R package for Structural Equation Modeling and Confirmatory Network Analysis.</p>
      <p>Developed by <a href="about.html">Sacha Epskamp</a>.</p>
    </div>
    <div>
      <h4>Links</h4>
      <ul>
        <li><a href="https://github.com/SachaEpskamp/psychonetrics">GitHub Repository</a></li>
        <li><a href="https://cran.r-project.org/package=psychonetrics">CRAN</a></li>
        <li><a href="https://github.com/SachaEpskamp/psychonetrics/issues">Report a Bug</a></li>
      </ul>
    </div>
    <div>
      <h4>Affiliation</h4>
      <img src="img/nus-logo-blue.png" alt="National University of Singapore" class="nus-logo-footer">
      <p>National University of Singapore<br>Methods, Data Science, and AI Lab</p>
    </div>
  </div>
  <div class="footer-bottom">
    <p>&copy; 2026 Sacha Epskamp. Built with plain HTML &amp; CSS.</p>
  </div>
</footer>

<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
<script src="js/main.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false}
      ],
      throwOnError: false
    });
  });
</script>
</body>
</html>
